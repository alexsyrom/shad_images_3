{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "theano.config.openmp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('finetuning-train/gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.png</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.png</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.png</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.png</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.png</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  class_id\n",
       "0  0000.png        50\n",
       "1  0001.png        24\n",
       "2  0002.png        25\n",
       "3  0003.png        37\n",
       "4  0004.png        13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename    2499.png\n",
       "class_id          50\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename    0000.png\n",
       "class_id           1\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Растянем/сожмём изображения, пока большая из сторон не станет равна SIDE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIDE_SIZE = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и дополним изображение до квадрата, заполняя отсутствующие клетки CVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVAL = 255 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings\n",
    "import skimage.color\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(input_dir, output_dir):\n",
    "    files = sorted([f for f in listdir(input_dir) if isfile(join(input_dir, f))])\n",
    "    for file in files:\n",
    "        img = io.imread(join(input_dir, file))\n",
    "        if img.ndim == 2:\n",
    "            img = skimage.color.gray2rgb(img)\n",
    "        factor = min([SIDE_SIZE / img.shape[i] for i in range(2)])\n",
    "        resized_img = skimage.transform.rescale(img, factor,\n",
    "                                               mode='constant', cval=CVAL, preserve_range=True)\n",
    "        square_image = np.zeros((SIDE_SIZE, SIDE_SIZE, 3), dtype=np.float64) + CVAL\n",
    "        square_image[(SIDE_SIZE - resized_img.shape[0]) // 2 :\n",
    "                     resized_img.shape[0] + (SIDE_SIZE - resized_img.shape[0]) // 2,\n",
    "                    (SIDE_SIZE - resized_img.shape[1]) // 2 :\n",
    "                     resized_img.shape[1] + (SIDE_SIZE - resized_img.shape[1]) // 2] = resized_img\n",
    "        resized_img = square_image.astype(np.uint8)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            io.imsave(join(output_dir, file), resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 5min, total: 7min 30s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resize('finetuning-train/images/', 'finetuning-train/resized250/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.3 s, sys: 1min, total: 1min 31s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resize('finetuning-test/images/', 'finetuning-test/resized250/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Раскидаем train по папочкам-классам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dirs(work_dir):\n",
    "    for index in range(1, 51):\n",
    "        os.mkdir(join(work_dir, \"{:02d}\".format(index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_dirs('finetuning-train/resized250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in labels.itertuples():\n",
    "    shutil.move(join('finetuning-train/resized250', row.filename), \n",
    "                join('finetuning-train/resized250', \"{:02d}\".format(row.class_id), row.filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь организуем такую же по структуре папку validation, и переместим туда по 10 случайных фотографий из каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_dirs('finetuning-train/validation250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_validation(input_dir, output_dir):\n",
    "    files = random.sample([f for f in listdir(input_dir) if isfile(join(input_dir, f))], 10)\n",
    "    for file in files:\n",
    "        shutil.move(join(input_dir, file), join(output_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(1, 51):\n",
    "    make_validation(join('finetuning-train/resized250', \"{:02d}\".format(index)),\n",
    "                    join('finetuning-train/validation250', \"{:02d}\".format(index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам понадобятся DataGenerator'ы для обучения и валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=20.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2,\n",
    "                     fill_mode='constant',\n",
    "                     cval=CVAL,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Напишем обёртку, которая будет вызывать prepocess_input для картинок из генератора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def preprocessed_datagen(datagen):\n",
    "    for x, y in datagen:\n",
    "        yield preprocess_input(x), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 50 classes.\n",
      "Found 500 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "\n",
    "train_gen = preprocessed_datagen(ImageDataGenerator(**data_gen_args).flow_from_directory(\n",
    "            'finetuning-train/resized250', target_size=(SIDE_SIZE, SIDE_SIZE), class_mode='categorical',\n",
    "             batch_size=batch_size, shuffle=True, seed=10))\n",
    "\n",
    "validation_gen = preprocessed_datagen(ImageDataGenerator(**data_gen_args).flow_from_directory(\n",
    "                 'finetuning-train/validation250', target_size=(SIDE_SIZE, SIDE_SIZE), class_mode='categorical',\n",
    "                 batch_size=batch_size, shuffle=True, seed=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать ResNet50. Для начала снимем полносвязные слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Subtensor{int64}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Subtensor{int64}.0)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, \n",
    "                         input_tensor=Input(shape=(SIDE_SIZE, SIDE_SIZE, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 zeropadding2d_1\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 activation_1\n",
      "5 maxpooling2d_1\n",
      "6 res2a_branch2a\n",
      "7 bn2a_branch2a\n",
      "8 activation_2\n",
      "9 res2a_branch2b\n",
      "10 bn2a_branch2b\n",
      "11 activation_3\n",
      "12 res2a_branch2c\n",
      "13 res2a_branch1\n",
      "14 bn2a_branch2c\n",
      "15 bn2a_branch1\n",
      "16 merge_1\n",
      "17 activation_4\n",
      "18 res2b_branch2a\n",
      "19 bn2b_branch2a\n",
      "20 activation_5\n",
      "21 res2b_branch2b\n",
      "22 bn2b_branch2b\n",
      "23 activation_6\n",
      "24 res2b_branch2c\n",
      "25 bn2b_branch2c\n",
      "26 merge_2\n",
      "27 activation_7\n",
      "28 res2c_branch2a\n",
      "29 bn2c_branch2a\n",
      "30 activation_8\n",
      "31 res2c_branch2b\n",
      "32 bn2c_branch2b\n",
      "33 activation_9\n",
      "34 res2c_branch2c\n",
      "35 bn2c_branch2c\n",
      "36 merge_3\n",
      "37 activation_10\n",
      "38 res3a_branch2a\n",
      "39 bn3a_branch2a\n",
      "40 activation_11\n",
      "41 res3a_branch2b\n",
      "42 bn3a_branch2b\n",
      "43 activation_12\n",
      "44 res3a_branch2c\n",
      "45 res3a_branch1\n",
      "46 bn3a_branch2c\n",
      "47 bn3a_branch1\n",
      "48 merge_4\n",
      "49 activation_13\n",
      "50 res3b_branch2a\n",
      "51 bn3b_branch2a\n",
      "52 activation_14\n",
      "53 res3b_branch2b\n",
      "54 bn3b_branch2b\n",
      "55 activation_15\n",
      "56 res3b_branch2c\n",
      "57 bn3b_branch2c\n",
      "58 merge_5\n",
      "59 activation_16\n",
      "60 res3c_branch2a\n",
      "61 bn3c_branch2a\n",
      "62 activation_17\n",
      "63 res3c_branch2b\n",
      "64 bn3c_branch2b\n",
      "65 activation_18\n",
      "66 res3c_branch2c\n",
      "67 bn3c_branch2c\n",
      "68 merge_6\n",
      "69 activation_19\n",
      "70 res3d_branch2a\n",
      "71 bn3d_branch2a\n",
      "72 activation_20\n",
      "73 res3d_branch2b\n",
      "74 bn3d_branch2b\n",
      "75 activation_21\n",
      "76 res3d_branch2c\n",
      "77 bn3d_branch2c\n",
      "78 merge_7\n",
      "79 activation_22\n",
      "80 res4a_branch2a\n",
      "81 bn4a_branch2a\n",
      "82 activation_23\n",
      "83 res4a_branch2b\n",
      "84 bn4a_branch2b\n",
      "85 activation_24\n",
      "86 res4a_branch2c\n",
      "87 res4a_branch1\n",
      "88 bn4a_branch2c\n",
      "89 bn4a_branch1\n",
      "90 merge_8\n",
      "91 activation_25\n",
      "92 res4b_branch2a\n",
      "93 bn4b_branch2a\n",
      "94 activation_26\n",
      "95 res4b_branch2b\n",
      "96 bn4b_branch2b\n",
      "97 activation_27\n",
      "98 res4b_branch2c\n",
      "99 bn4b_branch2c\n",
      "100 merge_9\n",
      "101 activation_28\n",
      "102 res4c_branch2a\n",
      "103 bn4c_branch2a\n",
      "104 activation_29\n",
      "105 res4c_branch2b\n",
      "106 bn4c_branch2b\n",
      "107 activation_30\n",
      "108 res4c_branch2c\n",
      "109 bn4c_branch2c\n",
      "110 merge_10\n",
      "111 activation_31\n",
      "112 res4d_branch2a\n",
      "113 bn4d_branch2a\n",
      "114 activation_32\n",
      "115 res4d_branch2b\n",
      "116 bn4d_branch2b\n",
      "117 activation_33\n",
      "118 res4d_branch2c\n",
      "119 bn4d_branch2c\n",
      "120 merge_11\n",
      "121 activation_34\n",
      "122 res4e_branch2a\n",
      "123 bn4e_branch2a\n",
      "124 activation_35\n",
      "125 res4e_branch2b\n",
      "126 bn4e_branch2b\n",
      "127 activation_36\n",
      "128 res4e_branch2c\n",
      "129 bn4e_branch2c\n",
      "130 merge_12\n",
      "131 activation_37\n",
      "132 res4f_branch2a\n",
      "133 bn4f_branch2a\n",
      "134 activation_38\n",
      "135 res4f_branch2b\n",
      "136 bn4f_branch2b\n",
      "137 activation_39\n",
      "138 res4f_branch2c\n",
      "139 bn4f_branch2c\n",
      "140 merge_13\n",
      "141 activation_40\n",
      "142 res5a_branch2a\n",
      "143 bn5a_branch2a\n",
      "144 activation_41\n",
      "145 res5a_branch2b\n",
      "146 bn5a_branch2b\n",
      "147 activation_42\n",
      "148 res5a_branch2c\n",
      "149 res5a_branch1\n",
      "150 bn5a_branch2c\n",
      "151 bn5a_branch1\n",
      "152 merge_14\n",
      "153 activation_43\n",
      "154 res5b_branch2a\n",
      "155 bn5b_branch2a\n",
      "156 activation_44\n",
      "157 res5b_branch2b\n",
      "158 bn5b_branch2b\n",
      "159 activation_45\n",
      "160 res5b_branch2c\n",
      "161 bn5b_branch2c\n",
      "162 merge_15\n",
      "163 activation_46\n",
      "164 res5c_branch2a\n",
      "165 bn5c_branch2a\n",
      "166 activation_47\n",
      "167 res5c_branch2b\n",
      "168 bn5c_branch2b\n",
      "169 activation_48\n",
      "170 res5c_branch2c\n",
      "171 bn5c_branch2c\n",
      "172 merge_16\n",
      "173 activation_49\n",
      "174 avg_pool\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим два полносвязных слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=5 * 10 ** -5\n",
    "decay=10 ** -7\n",
    "w_reg=5 * 10 ** -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu', W_regularizer=l2(w_reg))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu', W_regularizer=l2(w_reg))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(50, activation='softmax', W_regularizer=l2(w_reg))(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(#optimizer=SGD(lr=lr, decay=decay, nesterov=True, momentum=0.9),\n",
    "              optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy', 'categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 3816s - loss: 3.5402 - categorical_accuracy: 0.1827 - categorical_crossentropy: 3.4166 - val_loss: 2.0414 - val_categorical_accuracy: 0.3917 - val_categorical_crossentropy: 2.0414\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 3882s - loss: 1.9790 - categorical_accuracy: 0.4383 - categorical_crossentropy: 1.8599 - val_loss: 1.4818 - val_categorical_accuracy: 0.5350 - val_categorical_crossentropy: 1.4818\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 3757s - loss: 1.4290 - categorical_accuracy: 0.5930 - categorical_crossentropy: 1.3203 - val_loss: 1.3511 - val_categorical_accuracy: 0.5900 - val_categorical_crossentropy: 1.3511\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 3749s - loss: 1.1729 - categorical_accuracy: 0.6557 - categorical_crossentropy: 1.0797 - val_loss: 1.4466 - val_categorical_accuracy: 0.5617 - val_categorical_crossentropy: 1.4466\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 3743s - loss: 0.9874 - categorical_accuracy: 0.7070 - categorical_crossentropy: 0.9059 - val_loss: 1.3866 - val_categorical_accuracy: 0.6017 - val_categorical_crossentropy: 1.3866\n",
      "CPU times: user 10h 58min 31s, sys: 2h 34min 45s, total: 13h 33min 17s\n",
      "Wall time: 5h 18min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit_generator(\n",
    "        train_gen,\n",
    "        samples_per_epoch=3000,\n",
    "        nb_epoch=5,\n",
    "        validation_data=validation_gen,\n",
    "        nb_val_samples=600,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('5epoch_top_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Subtensor{int64}.0, Elemwise{add,no_inplace}.0, Elemwise{add,no_inplace}.0, Subtensor{int64}.0)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('5epoch_top_resnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучим некоторые последние res-блоки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала разморозим эти блоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:142]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[142:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём RMSprop с меньшим learning rate (по умолчанию lr=$10^{-3}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr=1 * 10 ** -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=lr),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy', 'categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В data-генераторах поменяем seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 50 classes.\n",
      "Found 500 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "\n",
    "train_gen = preprocessed_datagen(ImageDataGenerator(**data_gen_args).flow_from_directory(\n",
    "            'finetuning-train/resized250', target_size=(SIDE_SIZE, SIDE_SIZE), class_mode='categorical',\n",
    "             batch_size=batch_size, shuffle=True, seed=42))\n",
    "\n",
    "validation_gen = preprocessed_datagen(ImageDataGenerator(**data_gen_args).flow_from_directory(\n",
    "                 'finetuning-train/validation250', target_size=(SIDE_SIZE, SIDE_SIZE), class_mode='categorical',\n",
    "                 batch_size=batch_size, shuffle=True, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 4599s - loss: 0.5397 - categorical_accuracy: 0.8453 - categorical_crossentropy: 0.4632 - val_loss: 1.0111 - val_categorical_accuracy: 0.7200 - val_categorical_crossentropy: 1.0111\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 4770s - loss: 0.3335 - categorical_accuracy: 0.9173 - categorical_crossentropy: 0.2590 - val_loss: 1.0940 - val_categorical_accuracy: 0.7200 - val_categorical_crossentropy: 1.0940\n",
      "CPU times: user 5h 46min 26s, sys: 57min 11s, total: 6h 43min 37s\n",
      "Wall time: 2h 39min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist = model.fit_generator(\n",
    "        train_gen,\n",
    "        samples_per_epoch=3000,\n",
    "        nb_epoch=2,\n",
    "        validation_data=validation_gen,\n",
    "        nb_val_samples=600,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('2epoch_top_res_block_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем datagen для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_preprocessed_datagen(datagen):\n",
    "    for x in datagen:\n",
    "        yield preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "\n",
    "test_gen = test_preprocessed_datagen(ImageDataGenerator().flow_from_directory(\n",
    "            'finetuning-test/resized250/', target_size=(SIDE_SIZE, SIDE_SIZE), class_mode=None,\n",
    "             batch_size=batch_size, shuffle=False, seed=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим вероятности классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_SAMPLES_COUNT = 500\n",
    "probs = model.predict_generator(test_gen, val_samples=TEST_SAMPLES_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем вероятности в предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(probs, axis=1) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним предсказания в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame()\n",
    "df_preds['filename'] = [\"{:04d}.png\".format(index) for index in range(TEST_SAMPLES_COUNT)]\n",
    "df_preds['class_id'] = predictions\n",
    "\n",
    "df_preds.to_csv(\"csv/dense5_topres2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
